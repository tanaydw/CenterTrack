{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interracial-brunswick",
   "metadata": {},
   "source": [
    "# Inference:- Localization and Metadata Generation (Car A)\n",
    "\n",
    "Please make sure that you have installed the software before running this notebook. If you forgot to install, please refere to [INSTALL.ipynb](INSTALL.ipynb) notebook for installation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-programmer",
   "metadata": {},
   "source": [
    "The code below executes the first step, i.e. it takes an image from camera, which is prerocessed and fed as input to a 3D object detection algorithm. The network outputs all the essential information, such as object category, 3D bounding box and box orientation, that is required to exactly localize the object in a space and links it with a particular GPS coordinate. The entire GPS â†’ metadata mapping is stored as a dictionary and transferred to the cloud, which recreates and analyzes the data in real-time setting. \n",
    "\n",
    "<p align=\"center\"> <img src='images/car_a_pipeline.PNG' align=\"center\" height=\"230px\"> </p> \n",
    "\n",
    "**Important points to Note:-**\n",
    "\n",
    "- The output video is stored in *results* directory which is automatically created after inference runs successfully. Similarly, the metadata is stored in *metadata* directory. This can then be transferred to the cloud.\n",
    "\n",
    "- Please specify the location of weights of the model and the inference video for this step. This should be defined in the cell below.\n",
    "\n",
    "- The video is assumed to be from denso camera, which was provided as dataset by TCJP/TMC. If some other camera is used, then please change the focal length and video size accordingly for proper results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/demo.py tracking,ddd \\\n",
    "    --save_framerate 10 \\                             # FPS of output video\n",
    "    --track_thresh 0.3  \\                             # Threshold for detection\n",
    "    --test_focal_length 1323 \\                        # Focal length of the camera\n",
    "    --save_video \\                                    # Option to save the video or not\n",
    "    --resize_video --video_h 1282 --video_w 2090 \\    # Size of the input video\n",
    "    --skip_first 720 \\                                # How many frames to skip at the beginning\n",
    "    --demo \\                                          # path to the demo video\n",
    "    --load_model                                      # path to the model weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
